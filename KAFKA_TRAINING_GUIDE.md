# ğŸ“ Kafka Training Troubleshooting Guide

## ğŸ› Váº¥n Äá»: Model KhÃ´ng Há»c ÄÆ°á»£c Dá»¯ Liá»‡u

### Triá»‡u Chá»©ng
```bash
# API tráº£ vá» predictions rá»—ng
{"predictions":{"user_2":[]}, "status":"completed"}

# Model metadata cho tháº¥y ráº¥t Ã­t data
"n_users": 2,
"n_items": 3,
"n_interactions": 4
```

Máº·c dÃ¹ Kafka cÃ³ 52+ messages nhÆ°ng model chá»‰ há»c Ä‘Æ°á»£c 4 interactions!

---

## ğŸ” NguyÃªn NhÃ¢n

### 1. **Consumer Offset ÄÃ£ á» Cuá»‘i**
Khi AI Server khá»Ÿi Ä‘á»™ng, Kafka consumer Ä‘á»c tá»« offset hiá»‡n táº¡i (cuá»‘i topic). Náº¿u báº¡n Ä‘Ã£ generate data TRÆ¯á»šC KHI start AI server, consumer sáº½ khÃ´ng Ä‘á»c Ä‘Æ°á»£c messages cÅ©.

```
Timeline:
1. Generate 52 messages â†’ Kafka   âœ…
2. Start AI Server â†’ Consumer starts at offset 52 (end)  âš ï¸
3. Consumer waits for NEW messages (khÃ´ng Ä‘á»c 52 messages cÅ©)  âŒ
```

### 2. **Consumer KhÃ´ng Timeout**
Code hiá»‡n táº¡i dÃ¹ng `consumer.poll()` trong vÃ²ng láº·p vÃ´ háº¡n:
```python
while True:
    msg = consumer.poll(1.0)  # Chá» mÃ£i mÃ£i!
```

Äiá»u nÃ y khiáº¿n training task "treo" chá» messages má»›i.

### 3. **Data Format KhÃ´ng ÄÃºng**
Má»™t sá»‘ messages khÃ´ng pháº£i JSON:
```
user_id:user2 item_id:item2 rating:5  âŒ (text format)
{"user_id":"user1","item_id":"item1","rating":5}  âœ… (JSON)
```

Messages khÃ´ng pháº£i JSON sáº½ bá»‹ bá» qua.

---

## âœ… Giáº£i PhÃ¡p

### ğŸš€ **Quick Fix (Khuyáº¿n Nghá»‹)**

#### BÆ°á»›c 1: Dá»«ng AI Server
```bash
docker-compose stop ai_server
```

#### BÆ°á»›c 2: Reset Consumer Group Offset
```bash
# Chá» consumer inactive (10-15 giÃ¢y)
timeout 15

# Reset offset vá» Ä‘áº§u
docker exec vrecom_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group test_connection_consumer_group \
  --reset-offsets \
  --to-earliest \
  --topic test_connection_topic \
  --execute
```

**Output:**
```
GROUP                          TOPIC                 PARTITION  NEW-OFFSET
test_connection_consumer_group test_connection_topic 0          0
```

#### BÆ°á»›c 3: XÃ³a Model CÅ©
```bash
docker exec vrecom_ai_server rm -f models/kafka_test*
```

#### BÆ°á»›c 4: Generate FRESH Data
```bash
cd tests/kafka-server
python generate_training_data.py

# Chá»n option 3: Send to Kafka
# Nháº­p topic: test_connection_topic
# Chá»n sá»‘ lÆ°á»£ng messages (recommend: 100-500)
```

#### BÆ°á»›c 5: Kiá»ƒm Tra Messages
```bash
# Count messages
docker exec vrecom_kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic test_connection_topic

# Output: test_connection_topic:0:502 (502 messages)

# Sample messages
docker exec vrecom_kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic test_connection_topic \
  --from-beginning \
  --max-messages 5
```

Äáº£m báº£o táº¥t cáº£ messages Ä‘á»u lÃ  JSON format!

#### BÆ°á»›c 6: Start AI Server
```bash
docker-compose start ai_server

# Äá»£i 10 giÃ¢y Ä‘á»ƒ khá»Ÿi Ä‘á»™ng
timeout 10

# Check logs
docker-compose logs -f ai_server
```

#### BÆ°á»›c 7: Äá»£i Training Task Cháº¡y
Training task cháº¡y má»—i 60 giÃ¢y. Hoáº·c trigger manually (cáº§n auth).

**Xem logs:**
```bash
docker-compose logs --tail=200 ai_server | findstr kafka_test
```

TÃ¬m dÃ²ng nhÆ°:
```
Batch 1 processed for kafka_test (1 interactions)
Batch 2 processed for kafka_test (1 interactions)
...
Training completed successfully for kafka_test
Model kafka_test saved to models/kafka_test.pkl
```

#### BÆ°á»›c 8: Verify Model
```bash
# Check model metadata
docker exec vrecom_ai_server cat models/kafka_test_metadata.json

# Should see something like:
# "n_users": 20,
# "n_items": 50,
# "n_interactions": 500
```

#### BÆ°á»›c 9: Test Recommendations
```bash
# Replace user_1 with actual user from your data
curl "http://localhost:2030/api/v1/recommend?user_id=user_1&task_name=kafka_test&model_id=kafka_test&n=10"
```

**Expected output:**
```json
{
  "predictions": {
    "user_1": [
      {"item_id": "item_5", "score": 4.8},
      {"item_id": "item_12", "score": 4.6},
      ...
    ]
  },
  "status": "completed"
}
```

---

## ğŸ”§ **Advanced Fixes**

### Fix 1: Change Consumer Auto Offset Reset

Edit `restaurant_data.yaml`:
```yaml
kafka_test:
    brokers: kafka:9093
    group_id: test_connection_consumer_group
    topic: test_connection_topic
    type: messaging_queue
    rename_columns: ""
    auto_offset_reset: earliest  # Add this line
```

### Fix 2: Sá»­ dá»¥ng Unique Consumer Group

Má»—i láº§n train, dÃ¹ng group ID khÃ¡c:
```yaml
kafka_test:
    group_id: test_consumer_group_v2  # Change this
```

Consumer group má»›i sáº½ Ä‘á»c tá»« Ä‘áº§u topic.

### Fix 3: Monitor Consumer Lag

```bash
# Check consumer status
docker exec vrecom_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group test_connection_consumer_group
```

**Output:**
```
GROUP                          TOPIC      PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
test_connection_consumer_group test_...   0          502             502             0
```

- **LAG = 0**: Consumer Ä‘Ã£ Ä‘á»c háº¿t, Ä‘ang chá» messages má»›i
- **LAG > 0**: Consumer Ä‘ang Ä‘á»c messages cÅ© (good!)

---

## ğŸ“Š **Workflow ÄÃºng**

### Scenario 1: Training Láº§n Äáº§u

```bash
# 1. Start há»‡ thá»‘ng (KHÃ”NG cÃ³ model)
docker-compose up -d

# 2. Generate data VÃ€O Kafka
cd tests/kafka-server
python generate_training_data.py
# â†’ Send 500 messages to test_connection_topic

# 3. Äá»£i training task cháº¡y (60 giÃ¢y)
# HOáº¶C restart AI server Ä‘á»ƒ trigger ngay
docker-compose restart ai_server

# 4. Verify
curl "http://localhost:2030/api/v1/recommend?user_id=user_1&task_name=kafka_test&model_id=kafka_test&n=10"
```

### Scenario 2: Retrain Vá»›i Data Má»›i

```bash
# 1. Generate thÃªm data
python generate_training_data.py
# â†’ Send 200 more messages

# 2. Äá»£i task cháº¡y (auto má»—i 60s)
# Consumer sáº½ Ä‘á»c tá»« offset cuá»‘i cÃ¹ng (incremental)

# 3. Model Ä‘Æ°á»£c update vá»›i data má»›i
```

### Scenario 3: Full Retrain Tá»« Äáº§u

```bash
# 1. Stop AI server
docker-compose stop ai_server

# 2. Reset offset
docker exec vrecom_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group test_connection_consumer_group \
  --reset-offsets --to-earliest \
  --topic test_connection_topic --execute

# 3. Delete model
docker exec vrecom_ai_server rm -f models/kafka_test*

# 4. Start AI server
docker-compose start ai_server

# 5. Äá»£i training (60s)
```

---

## ğŸ¯ **Best Practices**

### 1. Data Generation

**âœ… DO:**
- Generate data vá»›i JSON format
- Include timestamp
- Use diverse users (10-100 users)
- Use diverse items (20-200 items)
- Generate 100-1000 interactions minimum

**âŒ DON'T:**
- Generate data sau khi AI server Ä‘Ã£ cháº¡y (sáº½ bá»‹ lag)
- Use text format
- Generate quÃ¡ Ã­t data (<20 interactions)

### 2. Consumer Groups

**âœ… DO:**
- Má»—i model/use case dÃ¹ng group ID riÃªng
- Reset offset khi cáº§n full retrain
- Monitor consumer lag thÆ°á»ng xuyÃªn

**âŒ DON'T:**
- DÃ¹ng chung group ID cho nhiá»u services
- Delete consumer group khi Ä‘ang active

### 3. Training

**âœ… DO:**
- Verify data trong Kafka trÆ°á»›c khi train
- Check model metadata sau training
- Test recommendations vá»›i nhiá»u users
- Monitor training logs

**âŒ DON'T:**
- Train vá»›i quÃ¡ Ã­t data
- Ignore training errors
- Train mÃ  khÃ´ng verify káº¿t quáº£

---

## ğŸ› **Common Issues**

### Issue 1: "predictions": []

**Cause:** User khÃ´ng cÃ³ trong training data

**Fix:**
```bash
# List all users in data
docker exec vrecom_kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic test_connection_topic \
  --from-beginning --max-messages 1000 | \
  grep -o '"user_id":"[^"]*"' | sort -u

# Test vá»›i user thá»±c táº¿
curl "http://localhost:2030/api/v1/recommend?user_id=user_1&..."
```

### Issue 2: Model cÃ³ quÃ¡ Ã­t interactions

**Cause:** Consumer offset Ä‘Ã£ á»Ÿ cuá»‘i, training task chá»‰ Ä‘á»c messages má»›i

**Fix:** Reset consumer offset (xem Quick Fix bÆ°á»›c 2)

### Issue 3: Training task "treo"

**Cause:** Kafka consumer Ä‘ang chá» messages má»›i mÃ£i mÃ£i

**Fix:** 
```bash
# Send má»™t message má»›i Ä‘á»ƒ trigger
echo '{"user_id":"dummy","item_id":"dummy","rating":1}' | \
  docker exec -i vrecom_kafka kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic test_connection_topic
```

### Issue 4: Consumer lag khÃ´ng giáº£m

**Cause:** AI server khÃ´ng Ä‘á»c messages

**Fix:**
```bash
# Check AI server logs
docker-compose logs -f ai_server

# Restart AI server
docker-compose restart ai_server
```

---

## ğŸ“ˆ **Monitoring**

### Check Training Progress

```bash
# Real-time logs
docker-compose logs -f ai_server | grep kafka_test

# Count batches processed
docker-compose logs ai_server | grep "Batch.*kafka_test" | wc -l
```

### Check Consumer Status

```bash
# Consumer group info
docker exec vrecom_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group test_connection_consumer_group

# Topic info
docker exec vrecom_kafka kafka-topics \
  --describe --topic test_connection_topic \
  --bootstrap-server localhost:9092
```

### Check Model Status

```bash
# Model files
docker exec vrecom_ai_server ls -lh models/ | grep kafka_test

# Model metadata
docker exec vrecom_ai_server cat models/kafka_test_metadata.json | jq
```

---

## ğŸ”— **Useful Commands**

```bash
# Delete all messages in topic (careful!)
docker exec vrecom_kafka kafka-topics \
  --delete --topic test_connection_topic \
  --bootstrap-server localhost:9092

# Recreate topic
docker exec vrecom_kafka kafka-topics \
  --create --topic test_connection_topic \
  --partitions 3 --replication-factor 1 \
  --bootstrap-server localhost:9092

# View Kafka UI
start http://localhost:8080

# Reset everything
docker-compose down -v
docker-compose up -d
```

---

## ğŸ“š **References**

- Main Kafka guide: `KAFKA_FIX_GUIDE.md`
- Quick fix: `KAFKA_QUICK_FIX.md`
- Commands cheatsheet: `KAFKA_CHEATSHEET.md`
- Full changelog: `CHANGELOG_KAFKA.md`

---

**Last Updated:** 2025-01-23  
**Version:** 1.0.0