# ğŸ”§ Kafka Broker Configuration Fix

## âŒ Váº¥n Äá»

Model `model_kafka` khÃ´ng há»c Ä‘Æ°á»£c data tá»« Kafka máº·c dÃ¹ Ä‘Ã£ generate dá»¯ liá»‡u.

### NguyÃªn NhÃ¢n

**File `restaurant_data.yaml` cÃ³ cáº¥u hÃ¬nh SAI:**
```yaml
kafka_test:
  brokers: localhost:9093  # âŒ SAI!
  type: messaging           # âŒ SAI!
```

**Giáº£i thÃ­ch:**
- `localhost:9093` - **KHÃ”NG Tá»’N Táº I** tá»« bÃªn trong Docker container
- Pháº£i dÃ¹ng `kafka:9093` (Docker service name)
- Type pháº£i lÃ  `messaging_queue` khÃ´ng pháº£i `messaging`

---

## âœ… Giáº£i PhÃ¡p

### BÆ°á»›c 1: Sá»­a Config File

**File:** `backend/ai_server/config/restaurant_data.yaml`

```yaml
kafka_test:
  brokers: kafka:9093          # âœ… ÄÃšNG - Docker internal
  group_id: test_connection_consumer_group
  rename_columns: ""
  topic: test_connection_topic
  type: messaging_queue        # âœ… ÄÃšNG
```

### BÆ°á»›c 2: Reset Consumer Offset

```bash
# Stop AI server
docker-compose stop ai_server

# Äá»£i consumer inactive (15 giÃ¢y)
timeout 15

# Reset offset vá» Ä‘áº§u
docker exec vrecom_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group test_connection_consumer_group \
  --reset-offsets --to-earliest \
  --topic test_connection_topic --execute
```

### BÆ°á»›c 3: XÃ³a Model CÅ© vÃ  Restart

```bash
# Start AI server
docker-compose start ai_server

# Sau khi AI server cháº¡y, xÃ³a model cÅ©
docker exec vrecom_ai_server rm -f models/model_kafka* models/kafka_test*

# Restart Ä‘á»ƒ Ã¡p dá»¥ng config má»›i
docker-compose restart ai_server
```

### BÆ°á»›c 4: Äá»£i Training (60 giÃ¢y)

```bash
# Monitor training progress
docker-compose logs -f ai_server | grep model_kafka

# Hoáº·c check batch progress
docker-compose logs --tail=200 ai_server | grep "Batch.*model_kafka"
```

### BÆ°á»›c 5: Verify Model

```bash
# Check model file
docker exec vrecom_ai_server ls -lh models/ | grep model_kafka

# Check model metadata
docker exec vrecom_ai_server cat models/model_kafka_metadata.json
```

Should see:
```json
{
  "n_users": 15+,
  "n_items": 30+,
  "n_interactions": 50+
}
```

### BÆ°á»›c 6: Test Recommendations

```bash
curl "http://localhost:2030/api/v1/recommend?user_id=user_1&model_id=model_kafka&n=10"
```

Expected:
```json
{
  "predictions": {
    "user_1": [
      {"item_id": "item_5", "score": 4.8},
      {"item_id": "item_12", "score": 4.6}
    ]
  },
  "status": "completed"
}
```

---

## ğŸ¯ Port Reference

| Location | Use | Broker Address |
|----------|-----|----------------|
| **Tá»« mÃ¡y host** (laptop/PC) | Generate data, test | `localhost:9092` |
| **Tá»« Docker container** (AI server) | Training, consume | `kafka:9093` |

### VÃ­ Dá»¥

**ÄÃºng:**
```bash
# Generate data tá»« mÃ¡y host
python generate_training_data.py
# â†’ Káº¿t ná»‘i: localhost:9092 âœ…

# AI server trong Docker
brokers: kafka:9093  âœ…
```

**Sai:**
```yaml
# AI server config
brokers: localhost:9093  âŒ (khÃ´ng tá»“n táº¡i trong container!)
brokers: localhost:9092  âŒ (external port, khÃ´ng access Ä‘Æ°á»£c)
```

---

## ğŸ“ Quick Commands

```bash
# Check Kafka topics
docker exec vrecom_kafka kafka-topics --list --bootstrap-server localhost:9092

# Count messages in topic
docker exec vrecom_kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 --topic test_connection_topic

# Check consumer lag
docker exec vrecom_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe --group test_connection_consumer_group

# Send test message (from host)
echo '{"user_id":"user_1","item_id":"item_5","rating":5}' | \
  docker exec -i vrecom_kafka kafka-console-producer \
  --bootstrap-server localhost:9092 --topic test_connection_topic

# View messages
docker exec vrecom_kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic test_connection_topic --from-beginning --max-messages 10
```

---

## âš¡ TL;DR

```bash
# 1. Sá»­a restaurant_data.yaml
#    localhost:9093 â†’ kafka:9093
#    messaging â†’ messaging_queue

# 2. Reset vÃ  restart
docker-compose stop ai_server
docker exec vrecom_kafka kafka-consumer-groups --bootstrap-server localhost:9092 \
  --group test_connection_consumer_group --reset-offsets --to-earliest \
  --topic test_connection_topic --execute
docker-compose start ai_server

# 3. Äá»£i 60 giÃ¢y Ä‘á»ƒ training cháº¡y

# 4. Test
curl "http://localhost:2030/api/v1/recommend?user_id=user_1&model_id=model_kafka&n=10"
```

---

**Status:** âœ… FIXED  
**Updated:** 2025-01-23  
**Files Changed:** `backend/ai_server/config/restaurant_data.yaml`
